"""
AI æä¾›å•†æ¶æ„ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨é‡æ„åçš„ AI æä¾›å•†æ¶æ„
"""

import asyncio
from typing import Dict, Any

# å¯¼å…¥é‡æ„åçš„æ¨¡å—
from core.model_providers.base_provider import provider_registry
from models.schemas.ai_provider import (
    OpenAIConfig,
    ClaudeConfig,
    UnifiedChatRequest,
    UnifiedMessage,
    MessageRole,
    ProviderType
)


async def demo_openai_provider():
    """æ¼”ç¤º OpenAI æä¾›å•†çš„ä½¿ç”¨"""
    print("=== OpenAI æä¾›å•†æ¼”ç¤º ===")
    
    # 1. åˆ›å»ºé…ç½®
    config_data = {
        "api_key": "sk-test123456789",  # æµ‹è¯•ç”¨çš„å‡å¯†é’¥
        "base_url": None,
        "timeout": 30.0,
        "max_retries": 3,
        "default_model": "gpt-3.5-turbo"
    }
    
    try:
        # 2. é€šè¿‡æ³¨å†Œè¡¨åˆ›å»ºæä¾›å•†å®ä¾‹
        provider = provider_registry.create_provider(
            ProviderType.OPENAI,
            config_data
        )
        
        print(f"âœ… åˆ›å»ºæä¾›å•†æˆåŠŸ: {provider.provider_type}")
        print(f"   æ”¯æŒçš„æ¨¡å‹: {provider.get_supported_models()}")
        print(f"   é»˜è®¤æ¨¡å‹: {provider.get_default_model()}")
        
        # 3. åˆ›å»ºèŠå¤©è¯·æ±‚
        request = UnifiedChatRequest(
            messages=[
                UnifiedMessage(
                    role=MessageRole.USER,
                    content="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
                )
            ],
            model="gpt-3.5-turbo",
            temperature=0.7,
            max_tokens=100
        )
        
        print(f"ğŸ“ è¯·æ±‚å†…å®¹: {request.messages[0].content}")
        
        # 4. å‘é€èŠå¤©è¯·æ±‚ï¼ˆè¿™é‡Œä¼šå¤±è´¥ï¼Œå› ä¸ºæ˜¯å‡å¯†é’¥ï¼‰
        try:
            response = await provider.chat(request)
            print(f"âœ… èŠå¤©å“åº”: {response.content}")
            print(f"   Tokenä½¿ç”¨: {response.usage}")
            print(f"   å»¶è¿Ÿ: {response.latency_ms}ms")
        except Exception as e:
            print(f"âŒ èŠå¤©è¯·æ±‚å¤±è´¥ï¼ˆé¢„æœŸçš„ï¼Œå› ä¸ºä½¿ç”¨äº†å‡å¯†é’¥ï¼‰: {str(e)}")
        
        # 5. è·å–æ€§èƒ½æŒ‡æ ‡
        metrics = provider.get_metrics()
        print(f"ğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
        print(f"   è¯·æ±‚æ¬¡æ•°: {metrics.request_count}")
        print(f"   æˆåŠŸæ¬¡æ•°: {metrics.success_count}")
        print(f"   é”™è¯¯æ¬¡æ•°: {metrics.error_count}")
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºæä¾›å•†å¤±è´¥: {str(e)}")


async def demo_provider_switching():
    """æ¼”ç¤ºæä¾›å•†åˆ‡æ¢çš„ä¾¿åˆ©æ€§"""
    print("\n=== æä¾›å•†åˆ‡æ¢æ¼”ç¤º ===")
    
    # ç»Ÿä¸€çš„èŠå¤©è¯·æ±‚
    request = UnifiedChatRequest(
        messages=[
            UnifiedMessage(
                role=MessageRole.USER,
                content="è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½"
            )
        ],
        model="default",  # ä½¿ç”¨é»˜è®¤æ¨¡å‹
        temperature=0.7
    )
    
    # ä¸åŒæä¾›å•†çš„é…ç½®
    providers_config = {
        ProviderType.OPENAI: {
            "api_key": "sk-test123456789",
            "default_model": "gpt-3.5-turbo"
        },
        # æ³¨æ„ï¼šClaude é…ç½®éœ€è¦ä¸åŒçš„ API key æ ¼å¼
        # ProviderType.CLAUDE: {
        #     "api_key": "sk-ant-test123456789",
        #     "default_model": "claude-3-haiku-20240307"
        # }
    }
    
    # éå†æ‰€æœ‰å·²æ³¨å†Œçš„æä¾›å•†
    for provider_type in provider_registry.list_providers():
        if provider_type in providers_config:
            try:
                print(f"\nğŸ”„ åˆ‡æ¢åˆ° {provider_type.value} æä¾›å•†")
                
                # åˆ›å»ºæä¾›å•†å®ä¾‹
                provider = provider_registry.create_provider(
                    provider_type,
                    providers_config[provider_type]
                )
                
                # ä½¿ç”¨ç›¸åŒçš„è¯·æ±‚æ ¼å¼
                request.model = provider.get_default_model()
                
                print(f"   ä½¿ç”¨æ¨¡å‹: {request.model}")
                print(f"   è¯·æ±‚å†…å®¹: {request.messages[0].content}")
                
                # å‘é€è¯·æ±‚ï¼ˆä¼šå¤±è´¥ï¼Œä½†å±•ç¤ºäº†ç»Ÿä¸€æ¥å£ï¼‰
                try:
                    response = await provider.chat(request)
                    print(f"   âœ… å“åº”: {response.content[:50]}...")
                except Exception as e:
                    print(f"   âŒ è¯·æ±‚å¤±è´¥ï¼ˆé¢„æœŸçš„ï¼‰: {type(e).__name__}")
                
            except Exception as e:
                print(f"   âŒ åˆ›å»ºæä¾›å•†å¤±è´¥: {str(e)}")


async def demo_stream_chat():
    """æ¼”ç¤ºæµå¼èŠå¤©"""
    print("\n=== æµå¼èŠå¤©æ¼”ç¤º ===")
    
    config_data = {
        "api_key": "sk-test123456789",
        "default_model": "gpt-3.5-turbo"
    }
    
    try:
        provider = provider_registry.create_provider(
            ProviderType.OPENAI,
            config_data
        )
        
        request = UnifiedChatRequest(
            messages=[
                UnifiedMessage(
                    role=MessageRole.USER,
                    content="è¯·å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„çŸ­è¯—"
                )
            ],
            model="gpt-3.5-turbo",
            stream=True
        )
        
        print("ğŸŒŠ å¼€å§‹æµå¼èŠå¤©...")
        print("ğŸ“ å“åº”å†…å®¹: ", end="")
        
        try:
            async for chunk in provider.chat_stream(request):
                print(chunk.delta, end="", flush=True)
            print()  # æ¢è¡Œ
        except Exception as e:
            print(f"\nâŒ æµå¼èŠå¤©å¤±è´¥ï¼ˆé¢„æœŸçš„ï¼‰: {type(e).__name__}")
            
    except Exception as e:
        print(f"âŒ åˆ›å»ºæä¾›å•†å¤±è´¥: {str(e)}")


async def demo_error_handling():
    """æ¼”ç¤ºé”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶"""
    print("\n=== é”™è¯¯å¤„ç†æ¼”ç¤º ===")
    
    # ä½¿ç”¨æ— æ•ˆçš„é…ç½®æ¥è§¦å‘é”™è¯¯
    invalid_configs = [
        {
            "name": "æ— æ•ˆçš„ API Key",
            "config": {
                "api_key": "invalid-key",  # ä¸ç¬¦åˆ OpenAI æ ¼å¼
                "default_model": "gpt-3.5-turbo"
            }
        },
        {
            "name": "ç©ºçš„ API Key",
            "config": {
                "api_key": "",
                "default_model": "gpt-3.5-turbo"
            }
        }
    ]
    
    for test_case in invalid_configs:
        print(f"\nğŸ§ª æµ‹è¯•: {test_case['name']}")
        try:
            provider = provider_registry.create_provider(
                ProviderType.OPENAI,
                test_case['config']
            )
            print("   âŒ åº”è¯¥å¤±è´¥ä½†æ²¡æœ‰å¤±è´¥")
        except Exception as e:
            print(f"   âœ… æ­£ç¡®æ•è·é”™è¯¯: {type(e).__name__}: {str(e)}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ AI æä¾›å•†æ¶æ„æ¼”ç¤º")
    print("=" * 50)
    
    # æ£€æŸ¥å·²æ³¨å†Œçš„æä¾›å•†
    registered_providers = provider_registry.list_providers()
    print(f"ğŸ“‹ å·²æ³¨å†Œçš„æä¾›å•†: {[p.value for p in registered_providers]}")
    
    # è¿è¡Œå„ç§æ¼”ç¤º
    await demo_openai_provider()
    await demo_provider_switching()
    await demo_stream_chat()
    await demo_error_handling()
    
    print("\nâœ¨ æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ’¡ é‡æ„åçš„æ¶æ„ä¼˜åŠ¿:")
    print("   âœ… ç»Ÿä¸€çš„æ¥å£è®¾è®¡")
    print("   âœ… ç±»å‹å®‰å…¨çš„é…ç½®ç®¡ç†")
    print("   âœ… å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶")
    print("   âœ… æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡æ”¶é›†")
    print("   âœ… æ˜“äºæ‰©å±•æ–°çš„ AI æä¾›å•†")


if __name__ == "__main__":
    asyncio.run(main())
