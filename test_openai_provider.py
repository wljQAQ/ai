"""
æµ‹è¯•é‡æ„åçš„ OpenAI Provider
"""

import asyncio
from core.model_providers.openai_provider import OpenAIProvider, OpenAIConfig, OpenAIRequest


async def test_openai_provider():
    """æµ‹è¯• OpenAI Provider çš„åŠŸèƒ½"""
    
    print("=== æµ‹è¯• OpenAI Provider é‡æ„ ===\n")
    
    # 1. æµ‹è¯•é…ç½®éªŒè¯
    print("1. æµ‹è¯•é…ç½®éªŒè¯:")
    print("-" * 40)
    
    # æœ‰æ•ˆé…ç½®
    valid_config = {
        "api_key": "sk-test123456789",
        "models": ["gpt-3.5-turbo", "gpt-4"],
        "timeout": 60.0,
        "max_retries": 3
    }
    
    try:
        provider = OpenAIProvider(valid_config)
        print("âœ… æœ‰æ•ˆé…ç½®åˆ›å»ºæˆåŠŸ")
        print(f"   æ”¯æŒçš„æ¨¡å‹: {provider.get_supported_models()}")
        print(f"   æä¾›å•†åç§°: {provider._get_provider_name()}")
    except Exception as e:
        print(f"âŒ é…ç½®åˆ›å»ºå¤±è´¥: {e}")
    
    # æ— æ•ˆé…ç½®
    invalid_config = {
        "api_key": "invalid-key",  # ä¸ä»¥ sk- å¼€å¤´
        "models": ["invalid-model"],  # ä¸æ”¯æŒçš„æ¨¡å‹
    }
    
    try:
        provider = OpenAIProvider(invalid_config)
        print("âŒ æ— æ•ˆé…ç½®ä¸åº”è¯¥åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âœ… æ— æ•ˆé…ç½®æ­£ç¡®è¢«æ‹’ç»: {e}")
    
    # 2. æµ‹è¯•è¯·æ±‚éªŒè¯
    print("\n2. æµ‹è¯•è¯·æ±‚éªŒè¯:")
    print("-" * 40)
    
    # æœ‰æ•ˆè¯·æ±‚
    valid_request = {
        "messages": [
            {"role": "user", "content": "Hello, how are you?"}
        ],
        "model": "gpt-3.5-turbo",
        "temperature": 0.7,
        "max_tokens": 100
    }
    
    try:
        request = OpenAIRequest(**valid_request)
        print("âœ… æœ‰æ•ˆè¯·æ±‚åˆ›å»ºæˆåŠŸ")
        print(f"   æ¶ˆæ¯æ•°é‡: {len(request.messages)}")
        print(f"   æ¨¡å‹: {request.model}")
        print(f"   æ¸©åº¦: {request.temperature}")
    except Exception as e:
        print(f"âŒ è¯·æ±‚åˆ›å»ºå¤±è´¥: {e}")
    
    # æ— æ•ˆè¯·æ±‚
    invalid_request = {
        "messages": [
            {"role": "invalid", "content": "Hello"}  # æ— æ•ˆè§’è‰²
        ],
        "temperature": 3.0,  # è¶…å‡ºèŒƒå›´
        "max_tokens": 10000  # è¶…å‡ºèŒƒå›´
    }
    
    try:
        request = OpenAIRequest(**invalid_request)
        print("âŒ æ— æ•ˆè¯·æ±‚ä¸åº”è¯¥åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âœ… æ— æ•ˆè¯·æ±‚æ­£ç¡®è¢«æ‹’ç»: {e}")
    
    # 3. æµ‹è¯•èŠå¤©åŠŸèƒ½ï¼ˆæ¨¡æ‹Ÿï¼‰
    print("\n3. æµ‹è¯•èŠå¤©åŠŸèƒ½:")
    print("-" * 40)
    
    try:
        provider = OpenAIProvider(valid_config)
        request = OpenAIRequest(**valid_request)
        
        # æµ‹è¯•åŒæ­¥èŠå¤©
        response = await provider.chat(request)
        print("âœ… èŠå¤©å“åº”æˆåŠŸ")
        print(f"   å“åº”ID: {response.id}")
        print(f"   å†…å®¹: {response.content}")
        print(f"   æ¨¡å‹: {response.model}")
        print(f"   Tokenä½¿ç”¨: {response.usage}")
        
        # æµ‹è¯•æµå¼èŠå¤©
        print("\n   æµå¼å“åº”:")
        async for chunk in provider.chat_stream(request):
            print(f"   ğŸ“ {chunk}", end="")
        print()  # æ¢è¡Œ
        
    except Exception as e:
        print(f"âŒ èŠå¤©æµ‹è¯•å¤±è´¥: {e}")
    
    # 4. æµ‹è¯•åºåˆ—åŒ–
    print("\n4. æµ‹è¯•åºåˆ—åŒ–:")
    print("-" * 40)
    
    try:
        config = OpenAIConfig(**valid_config)
        request = OpenAIRequest(**valid_request)
        
        # JSON åºåˆ—åŒ–
        config_json = config.model_dump_json()
        request_json = request.model_dump_json()
        
        print("âœ… åºåˆ—åŒ–æˆåŠŸ")
        print(f"   é…ç½®JSONé•¿åº¦: {len(config_json)} å­—ç¬¦")
        print(f"   è¯·æ±‚JSONé•¿åº¦: {len(request_json)} å­—ç¬¦")
        
        # ååºåˆ—åŒ–
        config_restored = OpenAIConfig.model_validate_json(config_json)
        request_restored = OpenAIRequest.model_validate_json(request_json)
        
        print("âœ… ååºåˆ—åŒ–æˆåŠŸ")
        print(f"   é…ç½®APIå¯†é’¥: {config_restored.api_key[:10]}...")
        print(f"   è¯·æ±‚æ¶ˆæ¯æ•°: {len(request_restored.messages)}")
        
    except Exception as e:
        print(f"âŒ åºåˆ—åŒ–æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(test_openai_provider())
